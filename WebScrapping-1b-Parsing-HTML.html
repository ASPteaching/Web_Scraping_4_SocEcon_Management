<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Web Scraping with R (1): Parsing HTML</title>
    <meta charset="utf-8" />
    <meta name="author" content="Alex Sanchez and Francesc Carmona" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="css4WScourse.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Web Scraping with R (1): Parsing HTML
]
.author[
### Alex Sanchez and Francesc Carmona
]
.institute[
### Genetics Microbiology and Statistics Department <br> Universitat de Barcelona
]
.date[
### October 2022
]

---


&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 28px;
    padding: 1em 2em 1em 2em;
}
.left-code {
  color: #777;
  width: 38%;
  height: 92%;
  float: left;
}
.right-plot {
  width: 60%;
  float: right;
  padding-left: 1%;
}
&lt;style&gt;
span.small {
  font-size: smaller;
}
&lt;/style&gt;




# Introduction

- Scraping HTML pages usually done in two steps: 
    - First, desired content from the Web is examined to determine if it is actionable to further analyses.
    - Second, HTML files are read and information is extracted from them. 

- Parsing HTML occurs at both steps
    - *by the browser* to display HTML content nicely, and also  
    - *by parsers in R* to construct useful representations of HTML documents in our programming environment.

---

# What is *parsing*

Parsing involves *breaking down a text into its component parts of speech with an explanation of the form, function, and syntactic relationship of each part*. [Wikipedia](https://en.wikipedia.org/wiki/Parsing).



```r
knitr::include_graphics("images/parseHTML.png")
```

&lt;img src="images/parseHTML.png" width="800" /&gt;
&lt;small&gt;
[HTML Parsing and Screen Scraping with the Simple HTML DOM Library](https://code.tutsplus.com/tutorials/html-parsing-and-screen-scraping-with-the-simple-html-dom-library--net-11856)
&lt;/small&gt;
---

# Reading vs parsing

- Not just a semantic difference: 
  + **reading** relies on functions that *do not care about the formal grammar that underlies HTML*, only recognizing the sequence of symbols included in the HTML file.
    
  + **parsing** employs programs that understand the special meaning of the mark-up structure reconstructing the HTML hierarchy within some R-specified structure.

---

# Getting data (1): *Reading* an HTML file

- HTML files are text files, thus, they can be read using the `readlines()` function:


```r
url &lt;- "http://www.r-datacollection.com/materials/html/fortunes.html"
fortunes &lt;- readLines(con = url)
head(fortunes, n=10)
```

```
##  [1] "&lt;!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML//EN\"&gt;"                            
##  [2] "&lt;html&gt; &lt;head&gt;"                                                               
##  [3] "&lt;title&gt;Collected R wisdoms&lt;/title&gt;"                                          
##  [4] "&lt;/head&gt;"                                                                     
##  [5] ""                                                                            
##  [6] "&lt;body&gt;"                                                                      
##  [7] "&lt;div id=\"R Inventor\" lang=\"english\" date=\"June/2003\"&gt;"                 
##  [8] "  &lt;h1&gt;Robert Gentleman&lt;/h1&gt;"                                                 
##  [9] "  &lt;p&gt;&lt;i&gt;'What we have is nice, but we need something very different'&lt;/i&gt;&lt;/p&gt;"
## [10] "  &lt;p&gt;&lt;b&gt;Source: &lt;/b&gt;Statistical Computing 2003, Reisensburg"
```

---

# __readLines()__ is a _reading_ function

- maps every line of the input file to a separate value in a character vector creating a flat representation of the document.

- it is *agnostic* about the different tag elements (name, attribute, values, etc.),

- it produces results that do not reflect the documentâ€™s internal hierarchy *as implied by the nested tags* in any sensible way.
    
---

# Getting data (2): parsing an HTML file

- To achieve a useful representation of HTML files, we need to employ a program that: 
    + understands the special meaning of the markup structures, and 
    + reconstructs the implied hierarchy of an HTML file within some R-specific data structure.
- This can be achieved by parser functions such as `rvest::read_html()` or `XML::htmlparse`.

---

# Parsing HTML with read_html


```r
library(rvest)
url &lt;- "http://www.r-datacollection.com/materials/html/fortunes.html"
myHTML&lt;- read_html (url)
myHTML
```

```
## {html_document}
## &lt;html&gt;
## [1] &lt;head&gt;\n&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;\n&lt;t ...
## [2] &lt;body&gt;\n&lt;div id="R Inventor" lang="english" date="June/2003"&gt;\n  &lt;h1&gt;Robert Gen ...
```

---

# The Document Object Model

- The structure of the parsed HTML object can be better viewed using `xml_structure` function from the `xml2` package.


```r
# Print the HTML excerpt with the xml_structure() function
xml2::xml_structure(myHTML)
```

- This representation is related with what we call the *Document Object Model (DOM)*.

- A Document Object Model is a _queryable data object_ that can be  built from any HTML file and is useful for further processing of document parts.

---

# A distraction: HTML tree structure

- A HTML document can be seen as a hierarchichal collection of tags which contain distinct elements.
- &lt;span class="small"&gt;Hint: Paste the source code of the _fortunes.html_ document in [This viewer](https://software.hixie.ch/utilities/js/live-dom-viewer/)&lt;/span&gt;


```r
knitr::include_graphics("images/htmlHierarchy.png")
```

&lt;img src="images/htmlHierarchy.png" width="70%" /&gt;

---

# DOM-style parsers

- Transformation from HTML code to the DOM is the task of a *DOM-style parsers*. 
&lt;!-- - Parsers belong to a *general class of domain-specific programs that traverse over symbol sequences and reconstruct the semantic structure of the document within a data object of the programming environment*. --&gt;
- There are two mainstream packages that can be used for parsing HTML code
  + [rvest package](https://github.com/hadley/rvest) by Hadley Wickam,
  + [XML package](https://cran.r-project.org/web/packages/XML/index.html) by Duncan Temple and Debbie Nolan.
  
- A few others can be found at [CRAN Task View: Web Technologies and Services](https://cran.r-project.org/web/views/WebTechnologies.html).
    &lt;!-- + See also the table and introduction at: (An R web crawler and scraper)[https://github.com/salimk/Rcrawler] --&gt;

---

&lt;!-- # Scrapping tools (I): The `XML` package --&gt;


&lt;!-- - The `XML` package provides an interface to `libxml2` a powerful parsing library written in C. --&gt;
&lt;!-- - The package is designed for two main purposes --&gt;
&lt;!--     + parsing xml / html content --&gt;
&lt;!--     + writing xml / html content (*we wonn't cover this*) --&gt;

&lt;!-- --- --&gt;

&lt;!-- # What can be achieved with `XML`? --&gt;

&lt;!-- - The `XML` package is useful at 4 major types of tasks: --&gt;

&lt;!--   1. parsing xml / html content --&gt;
&lt;!--   2. obtaining descriptive information about parsed contents --&gt;
&lt;!--   3. navigating the tree structure (ie *accessing its components*) --&gt;
&lt;!--   4. querying and extracting data from parsed contents --&gt;

&lt;!-- - The `XML` package can be used for both XML and HTML parsing.  --&gt;

&lt;!-- --- --&gt;


# Scraping tools: The `rvest` package

- `rvest` is an R package written by [Hadley Wickam](http://hadley.nz/) to _easily scrap web pages_
  - Wrappers around the 'xml2' and 'httr' packages to make it easy to download, and manipulate, HTML and XML
  - It is inspired in the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) python package.
  - It is designed to work with  [magrittr](https://github.com/tidyverse/magrittr) to simplify tasks.

- See more information on `rvest` at: 
 + [rvest package on CRAN](https://cran.r-project.org/web/packages/rvest/index.html)
 + [rvest documentation on DataCamp](https://www.rdocumentation.org/packages/rvest/versions/1.0.3)
    

---

# Basic `rvest` capabilities

- Get the data: Parse an html document from a url, a file on disk or a string containing html with `read_html()` **from he `xml2`package**.&lt;tab&gt;   [+info](https://www.rdocumentation.org/packages/xml2/versions/1.3.3/topics/read_xml)

- Extract elements using `html_element(s)()`.  [+info](https://www.rdocumentation.org/packages/rvest/versions/1.0.3/topics/html_element)

- Use `html_text2()` to extract the plain text contents of an HTML element. [+info](https://www.rdocumentation.org/packages/rvest/versions/1.0.3/topics/html_text2)

- Or use `html_attr(s)()` to retrieve the value of a single attribute. [+info](https://www.rdocumentation.org/packages/rvest/versions/1.0.3/topics/html_attr)

- Use `html_table` to read a table from within a page. [+info](https://www.rdocumentation.org/packages/rvest/versions/1.0.3/topics/html_table)
    
---

# More `rvest` capabilities

+ Get children from an element `html_children()`.

+ Extract, modify and submit forms with 
  -`html_form()`, `set_values()` and `submit_form()`.

+ Detect and repair encoding problems with:
  - `guess_encoding()` and `repair_encoding()`. 
  Then pass the correct encoding into `html()` as an argument.

---

# Examples (1): Read HTML

.pull-left[

```r
html_0 &lt;- '
&lt;html&gt; 
  &lt;body&gt; 
    &lt;h1&gt;Web scraping is cool&lt;/h1&gt;
    &lt;p&gt;It requires getting data and parsing it.&lt;/p&gt;
    &lt;p&gt;&lt;a href="https://aspteaching.github.io/WSWRCourse"&gt;A course on Web Scraping&lt;/a&gt; &lt;/p&gt;
  &lt;/body&gt; 
&lt;/html&gt;'
```
]
.pull-right[
- HTML data can be read with `read_html`.

```r
html_object &lt;- xml2::read_html(html_0)
show(html_0)
```
XML structure can be better viewed with:

```r
# Print the HTML excerpt with the xml_structure() function
xml_structure(html_0)
```
]

---
# Examples (2): html_elements()

.pull-left[

```r
list_of_links &lt;- '&lt;h3&gt;Useful links&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://wikipedia.org"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.ub.edu"&gt;UB&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://diba.cat"&gt;DiputaciÃ³ de Barcelona&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;'
```
]
.pull-right[
Extract all the a nodes from the bulleted list.

```r
links &lt;- list_of_links %&gt;% 
  read_html() %&gt;% 
  html_elements("a")
```
]

---
 
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
